# -- ¡¡¡IMPORTANTE!!! --
# Antes de ejecutar deben instalarse las librerías requests y BeautifulSoup desde la terminal. 
# Para ello, teniendo en cuenta que la versión de Python es 3.12, deben ejecutarse:
# >> pip installs requests
# >> pip installs bs4
# ----- LIBRERÍAS -----
# Se importa la librería requests para realizar la petición de conexión a la página web
import requests
# Se importa la librería Beautiful para realizar Web Scraping sobre la página web
import bs4
# ----- VARIABLES -----
# Estas variables representan los colores con los que se van a mostrar los mensajes por terminal
azul = "\33[1;36m"
blanco = "\33[1;37m"
amarillo = "\33[0;33m"
# ----- PROCEDIMIENTOS -----
    # ----- DEFINICIÓN DE LA PETICIÓN -----
    # Se inicializa el diccionario donde se almacenan las variables a extraer y sus valores
    # Se definen las cabeceras para la petición. Desde el modo inspeccionar del navegador se puede obtener el user-agent que utiliza
    # Se realiza la petición con la que se extraen los datos
    # Para ello, se muestra un mensaje por terminal indicando sobre qué url se va a realizar la petición
    # Se crea la petición con la url y las cabeceras definidas previamente. Además, se añade un timeout por si tardase demasiado tiempo en ejecutar la petición
    # Se imprime el código de respuesta obtenido de la petición
    # En caso de que la petición no sea exitosa
    # Salta una excepción con el mensaje de error y el código de estado correspondientes
    # Si todo va bien, se procede a extraer los datos mediante Web Scraping
    # ----- EXTRACCIÓN DE DATOS SIN BEAUTIFULSOUP -----
    # Existen variables que se pueden extraer directamente de la url desde la que se realiza la petición, como es el caso de la url del producto o el id del producto
    # Para extraer la url del producto, simplemente se extrae la url de la petición
    # El id del producto se localiza al final de la url hasta el caracter '/'. Para extraerlo, se puede obtener la url, partirla por '/' y extraer el último dato 
    # ----- EXTRACCIÓN DE DATOS CON BEAUTIFULSOUP -----
    # Para extraer las siguientes variables se requiere de Web Scraping y, por tanto, de la librería BeautifulSoup. 
    # Para ello, se define el objeto BeautifulSoup a partir del código que se encuentra en req.text y se convierte a HTML con "html.parser" 
    # La extracción de datos se debe hacer de forma minuciosa, inspeccionando la página y averiguando dónde están localizadas
    # El nombre del producto se obtiene de la siguiente manera:
    # - find("tipo de elemento", "nombre de la clase, id u objeto donde se almacene"): Localiza la primera coincidencia en el código HTML
    # - text: Convierte el resultado a texto
    # - strip(): Extrae el dato del texto 
    # Por último, el dato se almacena en el diccionario
    # La url de la imagen del producto se obtiene de la siguiente manera:
    # - find("tipo de elemento", "nombre de la clase, id u objeto donde se almacene"): Localiza la primera coincidencia en el código HTML
    # - attrs: Obtiene todos los parámetros que se encuentran almacenados en el objeto localizado
    # - get("donde se encuentra el dato"): Extrae el dato concreto de todos los parámetros extraídos con la instrucción anterior
    # Por último, el dato se almacena en el diccionario
    # Las plataformas del producto se obtienen de la siguiente manera:
    # - find("tipo de elemento", "nombre de la clase, id u objeto donde se almacene"): Localiza la primera coincidencia en el código HTML
    # - find_all("tipo de elemento", "nombre de la clase, id u objeto donde se almacene"): Localiza todos los valores que coincidan con la etiqueta, ya que 
    #   puede estar disponible para varias plataformas
    # Por cada elemento que se haya localizado, se extrae y se convierte a texto. Por último, se almacena en la colección
    # La valoración, como puede estar vacía, se debe tratar con una estructura try/except. Además, en la página desde la que se realiza el ejemplo, la valoración se
    # expresa en estrellas. La puntuación queda almacenada en el objeto HTML que está definido div class = "review-points-4".
    # Para extraer la valoración se hacen los siguientes pasos:
    # - find("tipo de elemento", "nombre de la clase, id u objeto donde se almacene"): Localiza la primera coincidencia en el código HTML
    # - attrs: Obtiene todos los parámetros que se encuentran almacenados en el objeto localizado
    # - get("donde se encuentra el dato"): Extrae el dato concreto de todos los parámetros extraídos con la instrucción anterior
    # Se extrae la valoración del último lugar de la cadena y se convierte a entero
    # Por último, el dato se almacena en el diccionario como un entero
    # Si no hay una valoración, se almacena un objeto vacío
    # Los precios, como pueden estar vacíos, se debe tratar con una estructura try/except. Además, en la página desde la que se realiza el ejemplo, los precios se
    # encuentran en un mismo objeto, por lo que deben separarse primero y tartarse después.
    # Para ello, se extrae el objeto precio con find()  
    # Para extraer el precio original se hacen los siguientes pasos:
    # - find("tipo de elemento", "nombre de la clase, id u objeto donde se almacene"): Localiza la primera coincidencia en el código HTML
    # - text: Convierte el objeto a texto
    # - replace("dato que se quiere reemplazar", "dato por el que se reemplaza"): Reemplaza los elementos que no son necesarios para convertirlos a float
    # Por último, se convierte el dato a float y se almacena
    # Si no hay un precio original (porque no está en stock), se almacena un objeto vacío
    # Para extraer el precio actual hay que extraer la parte entera y la parte decimal porque ambas están separadas. 
    # Para la parte entera se hacen los siguientes pasos:
    # - find("tipo de elemento", "nombre de la clase, id u objeto donde se almacene"): Localiza la primera coincidencia en el código HTML
    # - text: Convierte el objeto a texto
    # - strip(): Extrae el dato del texto 
    # - split(): Se separa el dato la parte
    # Para la parte decimal se hacen los siguientes pasos:
    # - find("tipo de elemento", "nombre de la clase, id u objeto donde se almacene"): Localiza la primera coincidencia en el código HTML
    # - text: Convierte el objeto a texto
    # - replace("dato que se quiere reemplazar", "dato por el que se reemplaza"): Reemplaza los elementos que no son necesarios para convertirlos a float
    # Por último, se juntan ambos datos, el resultado se convierte a float y se almacena
    # Si no hay un precio actual (porque no hay un descuento), se almacena un objeto vacío
    # Devuelve el diccionario creado
# ----- MAIN -----
    # Se define la url de la página web sobre la que se va a realizar Web Scraping
    # Se invoca al procedimiento datos_Scraping con la url y los resultados se almacenan en la variable datos
    # Del diccionario resultante se extraen los datos obtenidos y se realiza el tratamiento 
    # Para cada clave (que se muestra en mayúsculas), se muestra el valor correspondiente
    # Se termina el programa